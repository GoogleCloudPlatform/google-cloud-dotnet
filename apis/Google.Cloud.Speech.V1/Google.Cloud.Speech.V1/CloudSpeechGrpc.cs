// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: google/cloud/speech/v1/cloud_speech.proto
// Original file comments:
// Copyright 2016 Google Inc.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.
//
#region Designer generated code

using System;
using System.Threading;
using System.Threading.Tasks;
using Grpc.Core;

namespace Google.Cloud.Speech.V1 {
  /// <summary>
  ///  Service that implements Google Cloud Speech API.
  /// </summary>
  public static class Speech
  {
    static readonly string __ServiceName = "google.cloud.speech.v1.Speech";

    static readonly Marshaller<global::Google.Cloud.Speech.V1.RecognizeRequest> __Marshaller_RecognizeRequest = Marshallers.Create((arg) => global::Google.Protobuf.MessageExtensions.ToByteArray(arg), global::Google.Cloud.Speech.V1.RecognizeRequest.Parser.ParseFrom);
    static readonly Marshaller<global::Google.Cloud.Speech.V1.RecognizeResponse> __Marshaller_RecognizeResponse = Marshallers.Create((arg) => global::Google.Protobuf.MessageExtensions.ToByteArray(arg), global::Google.Cloud.Speech.V1.RecognizeResponse.Parser.ParseFrom);
    static readonly Marshaller<global::Google.Cloud.Speech.V1.NonStreamingRecognizeResponse> __Marshaller_NonStreamingRecognizeResponse = Marshallers.Create((arg) => global::Google.Protobuf.MessageExtensions.ToByteArray(arg), global::Google.Cloud.Speech.V1.NonStreamingRecognizeResponse.Parser.ParseFrom);

    static readonly Method<global::Google.Cloud.Speech.V1.RecognizeRequest, global::Google.Cloud.Speech.V1.RecognizeResponse> __Method_Recognize = new Method<global::Google.Cloud.Speech.V1.RecognizeRequest, global::Google.Cloud.Speech.V1.RecognizeResponse>(
        MethodType.DuplexStreaming,
        __ServiceName,
        "Recognize",
        __Marshaller_RecognizeRequest,
        __Marshaller_RecognizeResponse);

    static readonly Method<global::Google.Cloud.Speech.V1.RecognizeRequest, global::Google.Cloud.Speech.V1.NonStreamingRecognizeResponse> __Method_NonStreamingRecognize = new Method<global::Google.Cloud.Speech.V1.RecognizeRequest, global::Google.Cloud.Speech.V1.NonStreamingRecognizeResponse>(
        MethodType.Unary,
        __ServiceName,
        "NonStreamingRecognize",
        __Marshaller_RecognizeRequest,
        __Marshaller_NonStreamingRecognizeResponse);

    /// <summary>Service descriptor</summary>
    public static global::Google.Protobuf.Reflection.ServiceDescriptor Descriptor
    {
      get { return global::Google.Cloud.Speech.V1.CloudSpeechReflection.Descriptor.Services[0]; }
    }

    /// <summary>Base class for server-side implementations of Speech</summary>
    public abstract class SpeechBase
    {
      /// <summary>
      ///  Perform bidirectional streaming speech-recognition: receive results while
      ///  sending audio.
      /// </summary>
      public virtual global::System.Threading.Tasks.Task Recognize(IAsyncStreamReader<global::Google.Cloud.Speech.V1.RecognizeRequest> requestStream, IServerStreamWriter<global::Google.Cloud.Speech.V1.RecognizeResponse> responseStream, ServerCallContext context)
      {
        throw new RpcException(new Status(StatusCode.Unimplemented, ""));
      }

      /// <summary>
      ///  Perform non-streaming speech-recognition: receive results after all audio
      ///  has been sent and processed.
      /// </summary>
      public virtual global::System.Threading.Tasks.Task<global::Google.Cloud.Speech.V1.NonStreamingRecognizeResponse> NonStreamingRecognize(global::Google.Cloud.Speech.V1.RecognizeRequest request, ServerCallContext context)
      {
        throw new RpcException(new Status(StatusCode.Unimplemented, ""));
      }

    }

    /// <summary>Client for Speech</summary>
    public class SpeechClient : ClientBase<SpeechClient>
    {
      /// <summary>Creates a new client for Speech</summary>
      /// <param name="channel">The channel to use to make remote calls.</param>
      public SpeechClient(Channel channel) : base(channel)
      {
      }
      /// <summary>Creates a new client for Speech that uses a custom <c>CallInvoker</c>.</summary>
      /// <param name="callInvoker">The callInvoker to use to make remote calls.</param>
      public SpeechClient(CallInvoker callInvoker) : base(callInvoker)
      {
      }
      /// <summary>Protected parameterless constructor to allow creation of test doubles.</summary>
      protected SpeechClient() : base()
      {
      }
      /// <summary>Protected constructor to allow creation of configured clients.</summary>
      /// <param name="configuration">The client configuration.</param>
      protected SpeechClient(ClientBaseConfiguration configuration) : base(configuration)
      {
      }

      /// <summary>
      ///  Perform bidirectional streaming speech-recognition: receive results while
      ///  sending audio.
      /// </summary>
      public virtual AsyncDuplexStreamingCall<global::Google.Cloud.Speech.V1.RecognizeRequest, global::Google.Cloud.Speech.V1.RecognizeResponse> Recognize(Metadata headers = null, DateTime? deadline = null, CancellationToken cancellationToken = default(CancellationToken))
      {
        return Recognize(new CallOptions(headers, deadline, cancellationToken));
      }
      /// <summary>
      ///  Perform bidirectional streaming speech-recognition: receive results while
      ///  sending audio.
      /// </summary>
      public virtual AsyncDuplexStreamingCall<global::Google.Cloud.Speech.V1.RecognizeRequest, global::Google.Cloud.Speech.V1.RecognizeResponse> Recognize(CallOptions options)
      {
        return CallInvoker.AsyncDuplexStreamingCall(__Method_Recognize, null, options);
      }
      /// <summary>
      ///  Perform non-streaming speech-recognition: receive results after all audio
      ///  has been sent and processed.
      /// </summary>
      public virtual global::Google.Cloud.Speech.V1.NonStreamingRecognizeResponse NonStreamingRecognize(global::Google.Cloud.Speech.V1.RecognizeRequest request, Metadata headers = null, DateTime? deadline = null, CancellationToken cancellationToken = default(CancellationToken))
      {
        return NonStreamingRecognize(request, new CallOptions(headers, deadline, cancellationToken));
      }
      /// <summary>
      ///  Perform non-streaming speech-recognition: receive results after all audio
      ///  has been sent and processed.
      /// </summary>
      public virtual global::Google.Cloud.Speech.V1.NonStreamingRecognizeResponse NonStreamingRecognize(global::Google.Cloud.Speech.V1.RecognizeRequest request, CallOptions options)
      {
        return CallInvoker.BlockingUnaryCall(__Method_NonStreamingRecognize, null, options, request);
      }
      /// <summary>
      ///  Perform non-streaming speech-recognition: receive results after all audio
      ///  has been sent and processed.
      /// </summary>
      public virtual AsyncUnaryCall<global::Google.Cloud.Speech.V1.NonStreamingRecognizeResponse> NonStreamingRecognizeAsync(global::Google.Cloud.Speech.V1.RecognizeRequest request, Metadata headers = null, DateTime? deadline = null, CancellationToken cancellationToken = default(CancellationToken))
      {
        return NonStreamingRecognizeAsync(request, new CallOptions(headers, deadline, cancellationToken));
      }
      /// <summary>
      ///  Perform non-streaming speech-recognition: receive results after all audio
      ///  has been sent and processed.
      /// </summary>
      public virtual AsyncUnaryCall<global::Google.Cloud.Speech.V1.NonStreamingRecognizeResponse> NonStreamingRecognizeAsync(global::Google.Cloud.Speech.V1.RecognizeRequest request, CallOptions options)
      {
        return CallInvoker.AsyncUnaryCall(__Method_NonStreamingRecognize, null, options, request);
      }
      protected override SpeechClient NewInstance(ClientBaseConfiguration configuration)
      {
        return new SpeechClient(configuration);
      }
    }

    /// <summary>Creates service definition that can be registered with a server</summary>
    public static ServerServiceDefinition BindService(SpeechBase serviceImpl)
    {
      return ServerServiceDefinition.CreateBuilder()
          .AddMethod(__Method_Recognize, serviceImpl.Recognize)
          .AddMethod(__Method_NonStreamingRecognize, serviceImpl.NonStreamingRecognize).Build();
    }

  }
}
#endregion
