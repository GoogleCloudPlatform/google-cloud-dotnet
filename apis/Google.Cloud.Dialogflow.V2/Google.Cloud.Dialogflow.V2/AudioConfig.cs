// <auto-generated>
//     Generated by the protocol buffer compiler.  DO NOT EDIT!
//     source: google/cloud/dialogflow/v2/audio_config.proto
// </auto-generated>
#pragma warning disable 1591, 0612, 3021
#region Designer generated code

using pb = global::Google.Protobuf;
using pbc = global::Google.Protobuf.Collections;
using pbr = global::Google.Protobuf.Reflection;
using scg = global::System.Collections.Generic;
namespace Google.Cloud.Dialogflow.V2 {

  /// <summary>Holder for reflection information generated from google/cloud/dialogflow/v2/audio_config.proto</summary>
  public static partial class AudioConfigReflection {

    #region Descriptor
    /// <summary>File descriptor for google/cloud/dialogflow/v2/audio_config.proto</summary>
    public static pbr::FileDescriptor Descriptor {
      get { return descriptor; }
    }
    private static pbr::FileDescriptor descriptor;

    static AudioConfigReflection() {
      byte[] descriptorData = global::System.Convert.FromBase64String(
          string.Concat(
            "Ci1nb29nbGUvY2xvdWQvZGlhbG9nZmxvdy92Mi9hdWRpb19jb25maWcucHJv",
            "dG8SGmdvb2dsZS5jbG91ZC5kaWFsb2dmbG93LnYyGhxnb29nbGUvYXBpL2Fu",
            "bm90YXRpb25zLnByb3RvImYKFFZvaWNlU2VsZWN0aW9uUGFyYW1zEgwKBG5h",
            "bWUYASABKAkSQAoLc3NtbF9nZW5kZXIYAiABKA4yKy5nb29nbGUuY2xvdWQu",
            "ZGlhbG9nZmxvdy52Mi5Tc21sVm9pY2VHZW5kZXIiswEKFlN5bnRoZXNpemVT",
            "cGVlY2hDb25maWcSFQoNc3BlYWtpbmdfcmF0ZRgBIAEoARINCgVwaXRjaBgC",
            "IAEoARIWCg52b2x1bWVfZ2Fpbl9kYhgDIAEoARIaChJlZmZlY3RzX3Byb2Zp",
            "bGVfaWQYBSADKAkSPwoFdm9pY2UYBCABKAsyMC5nb29nbGUuY2xvdWQuZGlh",
            "bG9nZmxvdy52Mi5Wb2ljZVNlbGVjdGlvblBhcmFtcyLNAQoRT3V0cHV0QXVk",
            "aW9Db25maWcSRwoOYXVkaW9fZW5jb2RpbmcYASABKA4yLy5nb29nbGUuY2xv",
            "dWQuZGlhbG9nZmxvdy52Mi5PdXRwdXRBdWRpb0VuY29kaW5nEhkKEXNhbXBs",
            "ZV9yYXRlX2hlcnR6GAIgASgFElQKGHN5bnRoZXNpemVfc3BlZWNoX2NvbmZp",
            "ZxgDIAEoCzIyLmdvb2dsZS5jbG91ZC5kaWFsb2dmbG93LnYyLlN5bnRoZXNp",
            "emVTcGVlY2hDb25maWcqjQEKD1NzbWxWb2ljZUdlbmRlchIhCh1TU01MX1ZP",
            "SUNFX0dFTkRFUl9VTlNQRUNJRklFRBAAEhoKFlNTTUxfVk9JQ0VfR0VOREVS",
            "X01BTEUQARIcChhTU01MX1ZPSUNFX0dFTkRFUl9GRU1BTEUQAhIdChlTU01M",
            "X1ZPSUNFX0dFTkRFUl9ORVVUUkFMEAMqpAEKE091dHB1dEF1ZGlvRW5jb2Rp",
            "bmcSJQohT1VUUFVUX0FVRElPX0VOQ09ESU5HX1VOU1BFQ0lGSUVEEAASIwof",
            "T1VUUFVUX0FVRElPX0VOQ09ESU5HX0xJTkVBUl8xNhABEh0KGU9VVFBVVF9B",
            "VURJT19FTkNPRElOR19NUDMQAhIiCh5PVVRQVVRfQVVESU9fRU5DT0RJTkdf",
            "T0dHX09QVVMQA0KfAQoeY29tLmdvb2dsZS5jbG91ZC5kaWFsb2dmbG93LnYy",
            "QhBBdWRpb0NvbmZpZ1Byb3RvUAFaRGdvb2dsZS5nb2xhbmcub3JnL2dlbnBy",
            "b3RvL2dvb2dsZWFwaXMvY2xvdWQvZGlhbG9nZmxvdy92MjtkaWFsb2dmbG93",
            "+AEBogICREaqAhpHb29nbGUuQ2xvdWQuRGlhbG9nZmxvdy5WMmIGcHJvdG8z"));
      descriptor = pbr::FileDescriptor.FromGeneratedCode(descriptorData,
          new pbr::FileDescriptor[] { global::Google.Api.AnnotationsReflection.Descriptor, },
          new pbr::GeneratedClrTypeInfo(new[] {typeof(global::Google.Cloud.Dialogflow.V2.SsmlVoiceGender), typeof(global::Google.Cloud.Dialogflow.V2.OutputAudioEncoding), }, new pbr::GeneratedClrTypeInfo[] {
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dialogflow.V2.VoiceSelectionParams), global::Google.Cloud.Dialogflow.V2.VoiceSelectionParams.Parser, new[]{ "Name", "SsmlGender" }, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dialogflow.V2.SynthesizeSpeechConfig), global::Google.Cloud.Dialogflow.V2.SynthesizeSpeechConfig.Parser, new[]{ "SpeakingRate", "Pitch", "VolumeGainDb", "EffectsProfileId", "Voice" }, null, null, null),
            new pbr::GeneratedClrTypeInfo(typeof(global::Google.Cloud.Dialogflow.V2.OutputAudioConfig), global::Google.Cloud.Dialogflow.V2.OutputAudioConfig.Parser, new[]{ "AudioEncoding", "SampleRateHertz", "SynthesizeSpeechConfig" }, null, null, null)
          }));
    }
    #endregion

  }
  #region Enums
  /// <summary>
  /// Gender of the voice as described in
  /// [SSML voice element](https://www.w3.org/TR/speech-synthesis11/#edef_voice).
  /// </summary>
  public enum SsmlVoiceGender {
    /// <summary>
    /// An unspecified gender, which means that the client doesn't care which
    /// gender the selected voice will have.
    /// </summary>
    [pbr::OriginalName("SSML_VOICE_GENDER_UNSPECIFIED")] Unspecified = 0,
    /// <summary>
    /// A male voice.
    /// </summary>
    [pbr::OriginalName("SSML_VOICE_GENDER_MALE")] Male = 1,
    /// <summary>
    /// A female voice.
    /// </summary>
    [pbr::OriginalName("SSML_VOICE_GENDER_FEMALE")] Female = 2,
    /// <summary>
    /// A gender-neutral voice.
    /// </summary>
    [pbr::OriginalName("SSML_VOICE_GENDER_NEUTRAL")] Neutral = 3,
  }

  /// <summary>
  /// Audio encoding of the output audio format in Text-To-Speech.
  /// </summary>
  public enum OutputAudioEncoding {
    /// <summary>
    /// Not specified.
    /// </summary>
    [pbr::OriginalName("OUTPUT_AUDIO_ENCODING_UNSPECIFIED")] Unspecified = 0,
    /// <summary>
    /// Uncompressed 16-bit signed little-endian samples (Linear PCM).
    /// Audio content returned as LINEAR16 also contains a WAV header.
    /// </summary>
    [pbr::OriginalName("OUTPUT_AUDIO_ENCODING_LINEAR_16")] Linear16 = 1,
    /// <summary>
    /// MP3 audio.
    /// </summary>
    [pbr::OriginalName("OUTPUT_AUDIO_ENCODING_MP3")] Mp3 = 2,
    /// <summary>
    /// Opus encoded audio wrapped in an ogg container. The result will be a
    /// file which can be played natively on Android, and in browsers (at least
    /// Chrome and Firefox). The quality of the encoding is considerably higher
    /// than MP3 while using approximately the same bitrate.
    /// </summary>
    [pbr::OriginalName("OUTPUT_AUDIO_ENCODING_OGG_OPUS")] OggOpus = 3,
  }

  #endregion

  #region Messages
  /// <summary>
  /// Description of which voice to use for speech synthesis.
  /// </summary>
  public sealed partial class VoiceSelectionParams : pb::IMessage<VoiceSelectionParams> {
    private static readonly pb::MessageParser<VoiceSelectionParams> _parser = new pb::MessageParser<VoiceSelectionParams>(() => new VoiceSelectionParams());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<VoiceSelectionParams> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dialogflow.V2.AudioConfigReflection.Descriptor.MessageTypes[0]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public VoiceSelectionParams() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public VoiceSelectionParams(VoiceSelectionParams other) : this() {
      name_ = other.name_;
      ssmlGender_ = other.ssmlGender_;
      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public VoiceSelectionParams Clone() {
      return new VoiceSelectionParams(this);
    }

    /// <summary>Field number for the "name" field.</summary>
    public const int NameFieldNumber = 1;
    private string name_ = "";
    /// <summary>
    /// Optional. The name of the voice. If not set, the service will choose a
    /// voice based on the other parameters such as language_code and gender.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public string Name {
      get { return name_; }
      set {
        name_ = pb::ProtoPreconditions.CheckNotNull(value, "value");
      }
    }

    /// <summary>Field number for the "ssml_gender" field.</summary>
    public const int SsmlGenderFieldNumber = 2;
    private global::Google.Cloud.Dialogflow.V2.SsmlVoiceGender ssmlGender_ = 0;
    /// <summary>
    /// Optional. The preferred gender of the voice. If not set, the service will
    /// choose a voice based on the other parameters such as language_code and
    /// name. Note that this is only a preference, not requirement. If a
    /// voice of the appropriate gender is not available, the synthesizer should
    /// substitute a voice with a different gender rather than failing the request.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dialogflow.V2.SsmlVoiceGender SsmlGender {
      get { return ssmlGender_; }
      set {
        ssmlGender_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as VoiceSelectionParams);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(VoiceSelectionParams other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (Name != other.Name) return false;
      if (SsmlGender != other.SsmlGender) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (Name.Length != 0) hash ^= Name.GetHashCode();
      if (SsmlGender != 0) hash ^= SsmlGender.GetHashCode();
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (Name.Length != 0) {
        output.WriteRawTag(10);
        output.WriteString(Name);
      }
      if (SsmlGender != 0) {
        output.WriteRawTag(16);
        output.WriteEnum((int) SsmlGender);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (Name.Length != 0) {
        size += 1 + pb::CodedOutputStream.ComputeStringSize(Name);
      }
      if (SsmlGender != 0) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) SsmlGender);
      }
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(VoiceSelectionParams other) {
      if (other == null) {
        return;
      }
      if (other.Name.Length != 0) {
        Name = other.Name;
      }
      if (other.SsmlGender != 0) {
        SsmlGender = other.SsmlGender;
      }
      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 10: {
            Name = input.ReadString();
            break;
          }
          case 16: {
            ssmlGender_ = (global::Google.Cloud.Dialogflow.V2.SsmlVoiceGender) input.ReadEnum();
            break;
          }
        }
      }
    }

  }

  /// <summary>
  /// Configuration of how speech should be synthesized.
  /// </summary>
  public sealed partial class SynthesizeSpeechConfig : pb::IMessage<SynthesizeSpeechConfig> {
    private static readonly pb::MessageParser<SynthesizeSpeechConfig> _parser = new pb::MessageParser<SynthesizeSpeechConfig>(() => new SynthesizeSpeechConfig());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<SynthesizeSpeechConfig> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dialogflow.V2.AudioConfigReflection.Descriptor.MessageTypes[1]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SynthesizeSpeechConfig() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SynthesizeSpeechConfig(SynthesizeSpeechConfig other) : this() {
      speakingRate_ = other.speakingRate_;
      pitch_ = other.pitch_;
      volumeGainDb_ = other.volumeGainDb_;
      effectsProfileId_ = other.effectsProfileId_.Clone();
      voice_ = other.voice_ != null ? other.voice_.Clone() : null;
      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public SynthesizeSpeechConfig Clone() {
      return new SynthesizeSpeechConfig(this);
    }

    /// <summary>Field number for the "speaking_rate" field.</summary>
    public const int SpeakingRateFieldNumber = 1;
    private double speakingRate_;
    /// <summary>
    /// Optional. Speaking rate/speed, in the range [0.25, 4.0]. 1.0 is the normal
    /// native speed supported by the specific voice. 2.0 is twice as fast, and
    /// 0.5 is half as fast. If unset(0.0), defaults to the native 1.0 speed. Any
    /// other values &lt; 0.25 or > 4.0 will return an error.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public double SpeakingRate {
      get { return speakingRate_; }
      set {
        speakingRate_ = value;
      }
    }

    /// <summary>Field number for the "pitch" field.</summary>
    public const int PitchFieldNumber = 2;
    private double pitch_;
    /// <summary>
    /// Optional. Speaking pitch, in the range [-20.0, 20.0]. 20 means increase 20
    /// semitones from the original pitch. -20 means decrease 20 semitones from the
    /// original pitch.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public double Pitch {
      get { return pitch_; }
      set {
        pitch_ = value;
      }
    }

    /// <summary>Field number for the "volume_gain_db" field.</summary>
    public const int VolumeGainDbFieldNumber = 3;
    private double volumeGainDb_;
    /// <summary>
    /// Optional. Volume gain (in dB) of the normal native volume supported by the
    /// specific voice, in the range [-96.0, 16.0]. If unset, or set to a value of
    /// 0.0 (dB), will play at normal native signal amplitude. A value of -6.0 (dB)
    /// will play at approximately half the amplitude of the normal native signal
    /// amplitude. A value of +6.0 (dB) will play at approximately twice the
    /// amplitude of the normal native signal amplitude. We strongly recommend not
    /// to exceed +10 (dB) as there's usually no effective increase in loudness for
    /// any value greater than that.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public double VolumeGainDb {
      get { return volumeGainDb_; }
      set {
        volumeGainDb_ = value;
      }
    }

    /// <summary>Field number for the "effects_profile_id" field.</summary>
    public const int EffectsProfileIdFieldNumber = 5;
    private static readonly pb::FieldCodec<string> _repeated_effectsProfileId_codec
        = pb::FieldCodec.ForString(42);
    private readonly pbc::RepeatedField<string> effectsProfileId_ = new pbc::RepeatedField<string>();
    /// <summary>
    /// Optional. An identifier which selects 'audio effects' profiles that are
    /// applied on (post synthesized) text to speech. Effects are applied on top of
    /// each other in the order they are given.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public pbc::RepeatedField<string> EffectsProfileId {
      get { return effectsProfileId_; }
    }

    /// <summary>Field number for the "voice" field.</summary>
    public const int VoiceFieldNumber = 4;
    private global::Google.Cloud.Dialogflow.V2.VoiceSelectionParams voice_;
    /// <summary>
    /// Optional. The desired voice of the synthesized audio.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dialogflow.V2.VoiceSelectionParams Voice {
      get { return voice_; }
      set {
        voice_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as SynthesizeSpeechConfig);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(SynthesizeSpeechConfig other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (!pbc::ProtobufEqualityComparers.BitwiseDoubleEqualityComparer.Equals(SpeakingRate, other.SpeakingRate)) return false;
      if (!pbc::ProtobufEqualityComparers.BitwiseDoubleEqualityComparer.Equals(Pitch, other.Pitch)) return false;
      if (!pbc::ProtobufEqualityComparers.BitwiseDoubleEqualityComparer.Equals(VolumeGainDb, other.VolumeGainDb)) return false;
      if(!effectsProfileId_.Equals(other.effectsProfileId_)) return false;
      if (!object.Equals(Voice, other.Voice)) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (SpeakingRate != 0D) hash ^= pbc::ProtobufEqualityComparers.BitwiseDoubleEqualityComparer.GetHashCode(SpeakingRate);
      if (Pitch != 0D) hash ^= pbc::ProtobufEqualityComparers.BitwiseDoubleEqualityComparer.GetHashCode(Pitch);
      if (VolumeGainDb != 0D) hash ^= pbc::ProtobufEqualityComparers.BitwiseDoubleEqualityComparer.GetHashCode(VolumeGainDb);
      hash ^= effectsProfileId_.GetHashCode();
      if (voice_ != null) hash ^= Voice.GetHashCode();
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (SpeakingRate != 0D) {
        output.WriteRawTag(9);
        output.WriteDouble(SpeakingRate);
      }
      if (Pitch != 0D) {
        output.WriteRawTag(17);
        output.WriteDouble(Pitch);
      }
      if (VolumeGainDb != 0D) {
        output.WriteRawTag(25);
        output.WriteDouble(VolumeGainDb);
      }
      if (voice_ != null) {
        output.WriteRawTag(34);
        output.WriteMessage(Voice);
      }
      effectsProfileId_.WriteTo(output, _repeated_effectsProfileId_codec);
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (SpeakingRate != 0D) {
        size += 1 + 8;
      }
      if (Pitch != 0D) {
        size += 1 + 8;
      }
      if (VolumeGainDb != 0D) {
        size += 1 + 8;
      }
      size += effectsProfileId_.CalculateSize(_repeated_effectsProfileId_codec);
      if (voice_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(Voice);
      }
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(SynthesizeSpeechConfig other) {
      if (other == null) {
        return;
      }
      if (other.SpeakingRate != 0D) {
        SpeakingRate = other.SpeakingRate;
      }
      if (other.Pitch != 0D) {
        Pitch = other.Pitch;
      }
      if (other.VolumeGainDb != 0D) {
        VolumeGainDb = other.VolumeGainDb;
      }
      effectsProfileId_.Add(other.effectsProfileId_);
      if (other.voice_ != null) {
        if (voice_ == null) {
          voice_ = new global::Google.Cloud.Dialogflow.V2.VoiceSelectionParams();
        }
        Voice.MergeFrom(other.Voice);
      }
      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 9: {
            SpeakingRate = input.ReadDouble();
            break;
          }
          case 17: {
            Pitch = input.ReadDouble();
            break;
          }
          case 25: {
            VolumeGainDb = input.ReadDouble();
            break;
          }
          case 34: {
            if (voice_ == null) {
              voice_ = new global::Google.Cloud.Dialogflow.V2.VoiceSelectionParams();
            }
            input.ReadMessage(voice_);
            break;
          }
          case 42: {
            effectsProfileId_.AddEntriesFrom(input, _repeated_effectsProfileId_codec);
            break;
          }
        }
      }
    }

  }

  /// <summary>
  /// Instructs the speech synthesizer how to generate the output audio content.
  /// </summary>
  public sealed partial class OutputAudioConfig : pb::IMessage<OutputAudioConfig> {
    private static readonly pb::MessageParser<OutputAudioConfig> _parser = new pb::MessageParser<OutputAudioConfig>(() => new OutputAudioConfig());
    private pb::UnknownFieldSet _unknownFields;
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pb::MessageParser<OutputAudioConfig> Parser { get { return _parser; } }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public static pbr::MessageDescriptor Descriptor {
      get { return global::Google.Cloud.Dialogflow.V2.AudioConfigReflection.Descriptor.MessageTypes[2]; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    pbr::MessageDescriptor pb::IMessage.Descriptor {
      get { return Descriptor; }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public OutputAudioConfig() {
      OnConstruction();
    }

    partial void OnConstruction();

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public OutputAudioConfig(OutputAudioConfig other) : this() {
      audioEncoding_ = other.audioEncoding_;
      sampleRateHertz_ = other.sampleRateHertz_;
      synthesizeSpeechConfig_ = other.synthesizeSpeechConfig_ != null ? other.synthesizeSpeechConfig_.Clone() : null;
      _unknownFields = pb::UnknownFieldSet.Clone(other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public OutputAudioConfig Clone() {
      return new OutputAudioConfig(this);
    }

    /// <summary>Field number for the "audio_encoding" field.</summary>
    public const int AudioEncodingFieldNumber = 1;
    private global::Google.Cloud.Dialogflow.V2.OutputAudioEncoding audioEncoding_ = 0;
    /// <summary>
    /// Required. Audio encoding of the synthesized audio content.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dialogflow.V2.OutputAudioEncoding AudioEncoding {
      get { return audioEncoding_; }
      set {
        audioEncoding_ = value;
      }
    }

    /// <summary>Field number for the "sample_rate_hertz" field.</summary>
    public const int SampleRateHertzFieldNumber = 2;
    private int sampleRateHertz_;
    /// <summary>
    /// Optional. The synthesis sample rate (in hertz) for this audio. If not
    /// provided, then the synthesizer will use the default sample rate based on
    /// the audio encoding. If this is different from the voice's natural sample
    /// rate, then the synthesizer will honor this request by converting to the
    /// desired sample rate (which might result in worse audio quality).
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int SampleRateHertz {
      get { return sampleRateHertz_; }
      set {
        sampleRateHertz_ = value;
      }
    }

    /// <summary>Field number for the "synthesize_speech_config" field.</summary>
    public const int SynthesizeSpeechConfigFieldNumber = 3;
    private global::Google.Cloud.Dialogflow.V2.SynthesizeSpeechConfig synthesizeSpeechConfig_;
    /// <summary>
    /// Optional. Configuration of how speech should be synthesized.
    /// </summary>
    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public global::Google.Cloud.Dialogflow.V2.SynthesizeSpeechConfig SynthesizeSpeechConfig {
      get { return synthesizeSpeechConfig_; }
      set {
        synthesizeSpeechConfig_ = value;
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override bool Equals(object other) {
      return Equals(other as OutputAudioConfig);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public bool Equals(OutputAudioConfig other) {
      if (ReferenceEquals(other, null)) {
        return false;
      }
      if (ReferenceEquals(other, this)) {
        return true;
      }
      if (AudioEncoding != other.AudioEncoding) return false;
      if (SampleRateHertz != other.SampleRateHertz) return false;
      if (!object.Equals(SynthesizeSpeechConfig, other.SynthesizeSpeechConfig)) return false;
      return Equals(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override int GetHashCode() {
      int hash = 1;
      if (AudioEncoding != 0) hash ^= AudioEncoding.GetHashCode();
      if (SampleRateHertz != 0) hash ^= SampleRateHertz.GetHashCode();
      if (synthesizeSpeechConfig_ != null) hash ^= SynthesizeSpeechConfig.GetHashCode();
      if (_unknownFields != null) {
        hash ^= _unknownFields.GetHashCode();
      }
      return hash;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public override string ToString() {
      return pb::JsonFormatter.ToDiagnosticString(this);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void WriteTo(pb::CodedOutputStream output) {
      if (AudioEncoding != 0) {
        output.WriteRawTag(8);
        output.WriteEnum((int) AudioEncoding);
      }
      if (SampleRateHertz != 0) {
        output.WriteRawTag(16);
        output.WriteInt32(SampleRateHertz);
      }
      if (synthesizeSpeechConfig_ != null) {
        output.WriteRawTag(26);
        output.WriteMessage(SynthesizeSpeechConfig);
      }
      if (_unknownFields != null) {
        _unknownFields.WriteTo(output);
      }
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public int CalculateSize() {
      int size = 0;
      if (AudioEncoding != 0) {
        size += 1 + pb::CodedOutputStream.ComputeEnumSize((int) AudioEncoding);
      }
      if (SampleRateHertz != 0) {
        size += 1 + pb::CodedOutputStream.ComputeInt32Size(SampleRateHertz);
      }
      if (synthesizeSpeechConfig_ != null) {
        size += 1 + pb::CodedOutputStream.ComputeMessageSize(SynthesizeSpeechConfig);
      }
      if (_unknownFields != null) {
        size += _unknownFields.CalculateSize();
      }
      return size;
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(OutputAudioConfig other) {
      if (other == null) {
        return;
      }
      if (other.AudioEncoding != 0) {
        AudioEncoding = other.AudioEncoding;
      }
      if (other.SampleRateHertz != 0) {
        SampleRateHertz = other.SampleRateHertz;
      }
      if (other.synthesizeSpeechConfig_ != null) {
        if (synthesizeSpeechConfig_ == null) {
          synthesizeSpeechConfig_ = new global::Google.Cloud.Dialogflow.V2.SynthesizeSpeechConfig();
        }
        SynthesizeSpeechConfig.MergeFrom(other.SynthesizeSpeechConfig);
      }
      _unknownFields = pb::UnknownFieldSet.MergeFrom(_unknownFields, other._unknownFields);
    }

    [global::System.Diagnostics.DebuggerNonUserCodeAttribute]
    public void MergeFrom(pb::CodedInputStream input) {
      uint tag;
      while ((tag = input.ReadTag()) != 0) {
        switch(tag) {
          default:
            _unknownFields = pb::UnknownFieldSet.MergeFieldFrom(_unknownFields, input);
            break;
          case 8: {
            audioEncoding_ = (global::Google.Cloud.Dialogflow.V2.OutputAudioEncoding) input.ReadEnum();
            break;
          }
          case 16: {
            SampleRateHertz = input.ReadInt32();
            break;
          }
          case 26: {
            if (synthesizeSpeechConfig_ == null) {
              synthesizeSpeechConfig_ = new global::Google.Cloud.Dialogflow.V2.SynthesizeSpeechConfig();
            }
            input.ReadMessage(synthesizeSpeechConfig_);
            break;
          }
        }
      }
    }

  }

  #endregion

}

#endregion Designer generated code
